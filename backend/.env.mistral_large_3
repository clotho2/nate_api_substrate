# ============================================
# Mistral Large 3 Configuration (via OpenRouter)
# ============================================
# This is a sample configuration for testing Mistral Large 3
# Copy the relevant sections to your .env file

# ============================================
# OpenRouter API (Required)
# ============================================
# Get your free API key at: https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here
DEFAULT_LLM_MODEL=mistralai/mistral-large

# ============================================
# Mistral Large 3 Model Details
# ============================================
# Model: mistralai/mistral-large (Mistral Large 3 - 2512)
# - 41B active parameters (675B total with MoE)
# - 256K context window
# - Native function calling support
# - Multimodal capabilities (vision)
# - NOT a reasoning model (optimized for System 1 fast pattern matching)
# - Great for agentic workflows with tool calling

# ============================================
# SERVER CONFIGURATION
# ============================================
PORT=8284
HOST=0.0.0.0

# ============================================
# OPTIONAL: Ollama Services (Embeddings)
# ============================================
# If you have Ollama installed locally for embeddings:
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ============================================
# Configuration Steps
# ============================================
# 1. Copy this to .env (or merge with existing .env)
# 2. Add your OPENROUTER_API_KEY
# 3. Run: python configure_mistral_large_3.py
# 4. Start backend: cd backend && source venv/bin/activate && python api/server.py
# 5. Start frontend: cd frontend && npm run dev
# 6. Test at: http://localhost:5173

# ============================================
# Testing Function Calling
# ============================================
# Mistral Large 3 supports native function calling in OpenAI format.
# The substrate will automatically provide all available tools.
# Test by asking questions that require:
# - Memory operations (core_memory_append, archival_memory_search)
# - Web search (web_search)
# - Content fetching (fetch_webpage)
# - Multiple tool chains

# ============================================
# Known Limitations
# ============================================
# - NOT a reasoning model (no extended deliberative chains)
# - Best for fast pattern matching and tool calling
# - A reasoning version is coming soon from Mistral AI
